---
title: "RSDTest"
author: "Yichen Han"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r pkgs}
library(deepG)
library(ggplot2)
library(microseq)
library(seqinr)
library(dplyr)
library(caret)
set.seed(42)
source("genepermutation.R")
```

```{r init}
# delete folder: normal, sepcial, abnormal
unlink("normal", recursive = TRUE)
unlink("abnormal", recursive = TRUE)
unlink("special", recursive = TRUE)
```

```{r raw data}
rsd <- seqinr::read.fasta("rsd.FASTA", seqtype = "DNA")
rsd <- toupper(unlist(seqinr::getSequence(rsd)))
```

```{r genepermutation}
triplets <- tokenize_triplets(rsd)
keyed <- triplets_keying(triplets)
test <- GenePermutation(triplets, keyed, num.perm=15000, min.subs=10, max.subs=30,
                        spec.region=30:60)
test <- test %>%
  mutate(seq = sapply(seq, paste, collapse = ""))
table(test$label)
```

```{r split}
# perform random train-validation-test split:
# Create indices for the training set (let's say 60% of the data)
training_indices <- createDataPartition(test$label, p = 0.6, list = FALSE)

# Create the training set
training_set <- test[training_indices, ]

# Split the remaining 40% into validation and test sets (50% each of the remaining)
remaining_indices <- setdiff(row.names(test), row.names(training_set))
remaining_set <- test[remaining_indices, ]
validation_indices <- createDataPartition(remaining_set$label, p = 0.5, list = FALSE)

# Create validation and test sets
validation_set <- remaining_set[validation_indices, ]
test_set <- remaining_set[-validation_indices, ]
```

```{r save into folders}
# create folders: normal, abnormal, special
## within each of them create train, validation, test folders
dir.create("normal")
dir.create("abnormal")
dir.create("special")
dir.create("normal/train")
dir.create("normal/validation")
dir.create("normal/test")
dir.create("abnormal/train")
dir.create("abnormal/validation")
dir.create("abnormal/test")
dir.create("special/train")
dir.create("special/validation")
dir.create("special/test")
# write each row into a FASTA file in corresponding folder, according to label
write_fasta <- function(data_set, set_name) {
  for (i in 1:nrow(data_set)) {
    # Define file path based on label and dataset type
    file_path <- paste0(data_set$label[i], "/", set_name, "/", i, ".fasta")
    
    # Create a data frame expected by microseq::writeFasta
    fasta_data <- data_set$seq[i]
    
    # Write FASTA file
    seqinr::write.fasta(fasta_data, file.out = file_path, names = i)
  }
}

# Apply the function to each dataset
write_fasta(training_set, "train")
write_fasta(validation_set, "validation")
write_fasta(test_set, "test")
```

```{r modelarchitecture}
model <- create_model_lstm_cnn(
  maxlen = 400,
  layer_lstm = NULL,
  layer_dense = c(3L),
  vocabulary_size = 4,
  kernel_size = c(12, 12, 12),
  filters = c(32, 64, 128),
  pool_size = c(3, 3, 3),
  learning_rate = 0.01
)
path_checkpoint <- file.path("checkpoints")
dir_path <- file.path("outputs")
unlink(paste0(path_checkpoint, "/rsdtest/*"))
unlink(paste0(path_checkpoint, "/lm_rsd_target_middle_lstm/*"))
if (!dir.exists(path_checkpoint)) dir.create(path_checkpoint)
if (!dir.exists(dir_path)) dir.create(dir_path)
```

```{r train}
path_normal_train <- file.path("normal/train")
path_normal_validation <- file.path("normal/validation")
path_abnormal_train <- file.path("abnormal/train")
path_abnormal_validation <- file.path("abnormal/validation")
path_special_train <- file.path("special/train")
path_special_validation <- file.path("special/validation")

hist <- train_model(train_type = "label_folder",
  model = model,
  path = c(path_normal_train, path_abnormal_train, path_special_train), # path to training files
  path_val = c(path_normal_validation, path_abnormal_validation, path_special_validation), # path to validation files
  vocabulary_label = c("normal", "abnormal", "special"),
  path_checkpoint = path_checkpoint,
  train_val_ratio = 0.2,
  run_name = "rsd-permutation",
  batch_size = 96, # number of samples to process in parallel
  steps_per_epoch = 45, # 1 epoch = 15 batches
  epochs = 10,
  save_best_only = FALSE,
  step = c(3, 3, 3))
plot(hist)
```

```{r evamodel}
path_special_test <- file.path("special/test")
path_normal_test <- file.path("normal/test")
path_abnormal_test <- file.path("abnormal/test")
eval_model <- evaluate_model(path_input = c(path_normal_test,
  path_abnormal_test, path_special_test),
  model = model,
  batch_size = 64,
  step = 5,
  vocabulary_label = list(c("normal", "abnormal", "special")),
  number_batches = 10,
  mode = "label_folder",
  verbose = FALSE
)

eval_model
```

```{r ig}
# create one instance with label special
special_seq <- permute_sequence(triplets, keyed, type="ok", min.subs=5, max.subs=30,
                                dict=codon.dict, spec.cond=FALSE, spec.region=NULL)
special_seq <- permute_sequence(special_seq, keyed, type="func", min.subs=20, max.subs=30,
                                dict=codon.dict, spec.cond=TRUE, spec.region=30:60)
special_seq <- paste(special_seq, collapse = "")
onehot_instance <-  seq_encoding_label(char_sequence = special_seq,
                                          maxlen = 400,
                                          start_ind = 1,
                                          vocabulary = c("A", "C", "G", "T"))
head(onehot_instance[1,,])
pred <- predict(model, onehot_instance, verbose = 0)
pred
ig <- integrated_gradients(
  input_seq = onehot_instance,
  baseline_type = "shuffle",
  target_class_idx = 3,
  model = model,
  num_baseline_repeats = 10)

heatmaps_integrated_grad(integrated_grads = ig,
                         input_seq = onehot_instance)

abs_sum <- rowSums(abs(as.array(ig)))
df <- data.frame(abs_sum = abs_sum, position = 1 : 400)
ggplot(df, aes(x = position, y = abs_sum)) + geom_smooth() + geom_point()
```