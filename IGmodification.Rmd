---
title: "IG Modification"
author: "Yichen Han"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r pkgs, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(deepG)
library(ggplot2)
library(microseq)
library(seqinr)
library(dplyr)
library(caret)
set.seed(42)
library(reticulate)
use_python("E:/miniconda/envs/r-reticulate/python.exe", required = TRUE)
source("genepermutation.R")
source("ig_modified.R")
```

## Flexible Baseline

We modified the source code of `deepG::integrated_gradients()` so that it now accepts any one-hot coded baseline array as an argument, thus allowing flexible comparison. It is currently only modified for the simplest case: no repeat, and input instance and baseline are not a list.

To showcase that a correctly chosen baseline can be crucial for model explanations, we load the same model as in RSDexport, and set two baselines:

1.  natural baseline: the documented gene sequence of *rsd*.
2.  abnormal baseline: a randomly functionally permuted copy, which should be predicted as "abnormal" by the model.

```{r baseline1}
# wild type baseline
rsd <- seqinr::read.fasta("rsd.FASTA", seqtype = "DNA")
rsd <- toupper(unlist(seqinr::getSequence(rsd)))
triplets <- tokenize_triplets(rsd)
keyed <- triplets_keying(triplets)
rsd_pasted <- paste(triplets, collapse = "")
onehot_baseline <-  seq_encoding_label(char_sequence = rsd_pasted,
                                          maxlen = 477,
                                          start_ind = 1,
                                          vocabulary = c("A", "C", "G", "T"))
```

```{r baseline2}
# abnormal baseline
bs_abn <- permute_sequence(triplets, type="ok", min.subs=10, max.subs=30,
                                dict=codon.dict, spec.cond=FALSE, spec.region=NULL)
bs_abn <- permute_sequence(bs_abn, type="func", min.subs=10, max.subs=30,
                                dict=codon.dict, spec.cond=FALSE, spec.region=30:60)
bsabn_pasted <- paste(bs_abn, collapse = "")
chars <- strsplit(bsabn_pasted, "")[[1]]
# Create triplets
trip_abn <- sapply(seq(1, length(chars), by = 3), function(i) {
  paste(chars[i:min(i+2, length(chars))], collapse = "")
})
keyed_abn <- triplets_keying(trip_abn)
onehot_bsabn <-  seq_encoding_label(char_sequence = bsabn_pasted,
                                          maxlen = 477,
                                          start_ind = 1,
                                          vocabulary = c("A", "C", "G", "T"))
```

```{r load model}
checkpoint_path <- file.path("checkpoints")
dir_path <- file.path("outputs")
run_name <- "rsd-permutation_39"
model <- load_cp(paste0(checkpoint_path, "/", run_name), 
                 cp_filter = "last_ep")
```

After modification, the IG call is the following:

```{r igexample, eval=FALSE, echo=TRUE}
ig <- ig_modified(
  input_seq = onehot_instance,
  baseline_type = "modify",
  baseline_onehot = onehot_baseline,
  target_class_idx = 3,
  model = model,
  num_baseline_repeats = 1)
```

```{r ig1}
instance <- permute_sequence(triplets, type="ok", min.subs=10, max.subs=30,
                                dict=codon.dict, spec.cond=FALSE, spec.region=NULL)
instance <- permute_sequence(instance, type="func", min.subs=10, max.subs=30,
                                dict=codon.dict, spec.cond=TRUE, spec.region=30:60)
instance_pasted <- paste(instance, collapse = "")
onehot_instance <-  seq_encoding_label(char_sequence = instance_pasted,
                                          maxlen = 477,
                                          start_ind = 1,
                                          vocabulary = c("A", "C", "G", "T"))
pred <- predict(model, onehot_instance, verbose = 0)
pred
ig <- ig_modified(
  input_seq = onehot_instance,
  baseline_type = "modify",
  baseline_onehot = onehot_baseline,
  target_class_idx = 3,
  model = model,
  num_baseline_repeats = 1)

heatmaps_integrated_grad(integrated_grads = ig,
                         input_seq = onehot_instance)
sum <- rowSums(as.array(ig))
abs_sum <- rowSums(abs(as.array(ig)))
df <- data.frame(abs_sum = abs_sum, sum=sum, position = 1 : 477)

ggplot(df, aes(x = position, y = sum)) + geom_rect(aes(xmin = 90, xmax = 180, ymin = -Inf, ymax = Inf), fill = "lightblue", alpha = 0.2) + geom_point() + theme_bw()
```

We see exactly what we expected -- high importance assigned to the targeted area, while irrelevant positions usually have gradients near 0.

```{r ig2}
ig2 <- ig_modified(
  input_seq = onehot_instance,
  baseline_type = "modify",
  baseline_onehot = onehot_bsabn,
  target_class_idx = 3,
  model = model,
  num_baseline_repeats = 1)

heatmaps_integrated_grad(integrated_grads = ig2,
                         input_seq = onehot_instance)

sum <- rowSums(as.array(ig2))
abs_sum <- rowSums(abs(as.array(ig2)))
df2 <- data.frame(abs_sum = abs_sum, sum=sum, position = 1 : 477)

ggplot(df2, aes(x = position, y = sum)) + geom_rect(aes(xmin = 90, xmax = 180, ymin = -Inf, ymax = Inf), fill = "lightblue", alpha = 0.2) + geom_point() + theme_bw()
```

This is less clear when the baseline is the abnormal type, but we can see the methods clearly captures what matters and what does not.

```{r compress1, message=FALSE}
df_mod <- df %>%
  mutate(group = rep(1:(nrow(df) / 3), each = 3)) %>%
  group_by(group) %>%
  summarise(
    abs_sum_sum = sum(abs_sum),
    abs_sum_median = median(abs_sum),
    abs_sum_mean = mean(abs_sum),
    abs_sum_max = max(abs_sum),
    sum_sum = sum(sum),
    sum_median = median(sum),
    sum_mean = mean(sum)
  )

df2_mod <- df2 %>%
  mutate(group = rep(1:(nrow(df2) / 3), each = 3)) %>%
  group_by(group) %>%
  summarise(
    abs_sum_sum = sum(abs_sum),
    abs_sum_median = median(abs_sum),
    abs_sum_mean = mean(abs_sum),
    abs_sum_max = max(abs_sum),
    sum_sum = sum(sum),
    sum_median = median(sum),
    sum_mean = mean(sum)
  )

# Split instance (a string) into triplets (every third character)
chars <- strsplit(instance_pasted, "")[[1]]

# Create triplets
trip_instance <- sapply(seq(1, length(chars), by = 3), function(i) {
  paste(chars[i:min(i+2, length(chars))], collapse = "")
})

keyed_instance <- triplets_keying(trip_instance)

# Get the index of sequences at which trip_instance != triplets
index <- which(keyed_instance != keyed)

index2 <- which(keyed_instance != keyed_abn)

ggplot(df_mod, aes(x = group)) +
  geom_rect(aes(xmin = 30, xmax = 60, ymin = -Inf, ymax = Inf), fill = "lightblue", alpha = 0.2) +
  # draw points of max
  geom_point(aes(x = group, y = sum_sum), color = "blue") +
  geom_smooth(aes(y = sum_sum, color = "Sum"), method = "auto", se = FALSE) +
  geom_smooth(aes(y = sum_median, color = "Median"), method = "auto", se = FALSE) +
  geom_smooth(aes(y = sum_mean, color = "Mean"), method = "auto", se = FALSE) +
  scale_color_manual(values = c("Sum" = "blue", "Median" = "green", "Mean" = "orange")) +
  geom_vline(xintercept = index, color = "red", linetype = "dashed") +
  theme_bw() +
  labs(y = "Sum of IG", color = "Statistic", x = "AA Index",
       title = "Compared to wild type") +
  # set x region to 30:60 only
  coord_cartesian(xlim = c(30, 60))

ggplot(df2_mod, aes(x = group)) +
  geom_rect(aes(xmin = 30, xmax = 60, ymin = -Inf, ymax = Inf), fill = "grey", alpha = 0.2) +
  # draw points of max
  geom_point(aes(x = group, y = sum_sum), color = "blue") +
  geom_smooth(aes(y = sum_sum, color = "Sum"), method = "auto", se = FALSE) +
  geom_smooth(aes(y = sum_median, color = "Median"), method = "auto", se = FALSE) +
  geom_smooth(aes(y = sum_mean, color = "Mean"), method = "auto", se = FALSE) +
  scale_color_manual(values = c("Sum" = "blue", "Median" = "green", "Mean" = "orange")) +
  geom_vline(xintercept = index2, color = "lightgrey", linetype = "dashed") +
  theme_bw() +
  labs(y = "Sum of IG", color = "Statistic", x = "AA Index",
       title = "Compared to abnormal")
```

We display it again after compressing the information. Vertical lines indicate substitution spots.

```{r wobbleness}
mean_codon <- sapply(1:3, function(i) {
  mean(df$sum[seq(i, 477, by = 3)])
})
# plot with line. x:1,2,3, y: mean_codon
ggplot(data = data.frame(x = 1:3, y = mean_codon), aes(x = x, y = y)) +
  geom_line() +
  geom_point() +
  theme_bw() +
  labs(x = "Codon Position", y = "Mean Locus Sum") +
  # x tick only 1,2,3, integer
  scale_x_continuous(breaks = 1:3, minor_breaks = NULL, labels = c("1", "2", "3"))

codon_data <- data.frame(
  position = rep(1:3, each = length(df$sum) / 3),
  sum = unlist(lapply(1:3, function(i) df$sum[seq(i, 477, by = 3)]))
)
#omit rows where sum ==0
codon_data <- codon_data[codon_data$sum != 0, ]

# Box plot for each codon position
ggplot(codon_data, aes(x = factor(position), y = sum)) +
  geom_boxplot() +
  theme_bw() +
  labs(x = "Codon Position", y = "Locus Abs Sum") +
  scale_x_discrete(labels = c("1", "2", "3"))

lm_model <- lm(sum ~ factor(position), data = codon_data)

# Summarize the linear model
summary(lm_model)
```

Wobbleness is again present, this time with relative confidence. Whether this effect is persistent across scenarios, is a topic worth further studying. But we need to recognize the high randomness behind it.

```{r PCSIV1, cache=TRUE}
# ok-mutate based on instance, 100 times, saved to pcss_df
# just use permute_sequence, nothing else
pcss_df <- data.frame(permuted = instance_pasted)
for (i in 1:999) {
  permuted_instance <- permute_sequence(instance, type = "ok", min.subs = 80,
                                        max.subs = 120, dict = codon.dict,
                                        spec.cond = FALSE, spec.region = NULL)
  permuted_instance <- paste(permuted_instance, collapse = "")
  pcss_df <- rbind(pcss_df, data.frame(permuted = I(list(permuted_instance))))
}
list_onehot <- lapply(pcss_df$permuted, function(x) {
  seq_encoding_label(char_sequence = x, maxlen = 477, start_ind = 1, vocabulary = c("A", "C", "G", "T"))
})
```

```{r PCSIV2, cache=TRUE}
csv_file_path <- "pcssdata_igm.csv"

# Check if the CSV file already exists
if (file.exists(csv_file_path)) {
  # If it exists, read the CSV into result_df
  result_df <- read.csv(csv_file_path)
  message("Loaded result_df from existing CSV file.")
} else {
# Initialize an empty dataframe with the position column
  result_df <- data.frame(position = 1:477)

# Loop through each one-hot encoded instance in the list
  for (i in seq_along(list_onehot)) {
    onehot_instance <- list_onehot[[i]]
  
  # Compute Integrated Gradients
    igw <- ig_modified(
      input_seq = onehot_instance,
      baseline_type = "modify",
      baseline_onehot = onehot_baseline,
      target_class_idx = 3,
      model = model,
      num_baseline_repeats = 1)
  
  # Compute the absolute sum of the IG scores
    abs_sum <- rowSums(abs(as.array(igw)))
  
  # Add the abs_sum as a new column in the result_df
    result_df[[paste0("abssum", i)]] <- abs_sum
  }
  write.csv(result_df, csv_file_path, row.names = FALSE)
}
```

```{r PCSIV3, cache=TRUE}
calculate_mean_every_three_rows <- function(df) {
  # Calculate the number of groups (each group will consist of three rows)
  n_groups <- nrow(df) %/% 3
  
  # Initialize an empty list to store the means
  mean_list <- list()
  
  # Loop through each group and calculate the mean for each column
  for (i in 1:n_groups) {
    # Select the three rows corresponding to the current group
    rows <- df[((i-1) * 3 + 1):(i * 3), ]
    
    # Calculate the mean for each column in the current group
    mean_row <- colSums(rows)
    
    # Append the result to the list
    mean_list[[i]] <- mean_row
  }
  
  # Combine the results into a new dataframe
  mean_df <- do.call(rbind, mean_list)
  
  return(mean_df)
}

# Apply the function to result_df
result_df_mean <- calculate_mean_every_three_rows(result_df)

# Convert the result to a data frame with appropriate column names
result_df_mean <- as.data.frame(result_df_mean)
names(result_df_mean) <- names(result_df)
result_df_mean <- result_df_mean %>%
  dplyr::select(-position)

# Function to calculate the coefficient of variance (CV) for each row
calculate_cv_rowwise <- function(df) {
  # Apply the function to calculate CV (sd/mean) row-wise
  cv <- apply(df[-1], 1, function(row) {
    row_sd <- sd(row, na.rm=TRUE)
    row_mean <- mean(row, na.rm=TRUE)
    if (row_mean != 0) {
      return(row_sd / row_mean)
    } else {
      return(NA)  # Handle division by zero
    }
  })
  return(cv)
}
invtrans <- function(x) {
  return(1 / (1 + x))
}

# Apply the function to result_df_mean (excluding the first column "position")
rowwise_std <- calculate_cv_rowwise(result_df_mean)
pcss_final <- data.frame(position=1:length(rowwise_std), key = keyed_instance,
                         trip_instance, sig.cv=invtrans(rowwise_std))

# plot pcss_final, x:position, y:cv, draw a horizontal line for the mean(pcss_final$cv), and mark its y coordinate
ggplot(pcss_final, aes(x = position, y = sig.cv)) +
  geom_line() +
  geom_hline(yintercept = mean(pcss_final$sig.cv, na.rm=TRUE), linetype = "dashed", lwd=1, color = "red") +
  geom_point() +
  theme_bw() +
  labs(x = "AA Index", y = "PCSC Score")
```

We see that the model under correct explanation achieves much less consistency in treating synonymous codons than that of RSDexport report. The consistency is only about 0.5. Given the satisfactory size of data (15000), we speculate that the model can be improved in this regard.
